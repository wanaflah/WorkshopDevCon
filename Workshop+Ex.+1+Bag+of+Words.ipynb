{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import all the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Declare sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "example = [['i hate you', 'neg'],\n",
    "['i love you', 'pos'],\n",
    "['i really hate you', 'neg'],\n",
    "['i like you', 'pos']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change into numpy array, easy to use slicing to get all elements wise-row / wise-column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_matrix = np.array(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we make it unique and got unique count\n",
    "take second column elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unique_labels, unique_count = np.unique(example_matrix[:, 1], return_counts = True)\n",
    "# unique_labels = ['neg', 'pos']\n",
    "# unique_count = [2, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# change ['neg', 'pos'] into int value, to feed into any classifier\n",
    "# the int value depends on parameter we used on LabelEncoder instantiation, default is depend on sorting alphabets\n",
    "label_int = LabelEncoder().fit_transform(example_matrix[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get our list of texts from our example\n",
    "# copy to prevent any changes, if you got huge corpus, remove the copy to prevent huge memory consume\n",
    "texts = example_matrix[:, 0].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hate' 'i' 'like' 'love' 'really' 'you']\n",
      "(4, 5)\n"
     ]
    }
   ],
   "source": [
    "# change into bag-of-word\n",
    "# default is bag-of-word\n",
    "# but if you change it the skip parameters, it will become skip-gram-model, CountVectorizer(ngram_range = (1, 5))\n",
    "bag_counts = CountVectorizer().fit_transform(texts)\n",
    "print(np.unique((' '.join(texts.flatten().tolist())).split()))\n",
    "#unique_texts = np.unique((' '.join(texts.flatten().tolist())).split())\n",
    "print(bag_counts.shape)\n",
    "# (4, 5), not (4, 6), because the default regexp select tokens of 2\n",
    "# Example, sentence is 'I LOVE YOU YOU YOU', our vector got [0, 0, 0] represent 'I LOVE YOU'\n",
    "# that mean our vector for 'I LOVE YOU YOU YOU' is [1, 1, 3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 5)\n"
     ]
    }
   ],
   "source": [
    "bag_counts_tdidf = TfidfTransformer(smooth_idf = True).fit_transform(bag_counts)\n",
    "print(bag_counts_tdidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i hate you'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_matrix[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pos'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_matrix[1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = example_matrix[:,0].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['i hate you', 'i love you', 'i really hate you', 'i like you'], \n",
       "      dtype='<U17')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_texts = list(set(' '.join(texts.tolist()).split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_1  = np.zeros((1, len(unique_texts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  1.,  0.,  1.,  1.]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in example_matrix[0,0].split():\n",
    "    bow_1[0,unique_texts.index(i)] += 1\n",
    "    \n",
    "bow_1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  1.,  1.,  1.,  0.]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_2 = np.zeros((1, len(unique_texts)))\n",
    "for i in example_matrix[1,0].split():\n",
    "    bow_2[0,unique_texts.index(i)] += 1\n",
    "    \n",
    "bow_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hate', 'i', 'like', 'love', 'really', 'you']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_texts = np.unique((' '.join(texts.flatten().tolist())).split())\n",
    "unique_texts = unique_texts.tolist()\n",
    "unique_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.  ,  0.  ,  1.  ,  0.  ,  1.  ,  0.25]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_i = 4\n",
    "bow_1[0,unique_texts.index(i)] = bow_1[0,unique_texts.index(i)]/(total_i)*1.0\n",
    "bow_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(1) -1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/anaconda/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import sklearn.datasets\n",
    "import re\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# clear string\n",
    "def clearstring(string):\n",
    "    string = re.sub('[^A-Za-z0-9 ]+', '', string)\n",
    "    string = string.split(' ')\n",
    "    string = filter(None, string)\n",
    "    string = [y.strip() for y in string]\n",
    "    string = ' '.join(string)\n",
    "    return string\n",
    "\n",
    "# because of sklean.datasets read a document as a single element\n",
    "# so we want to split based on new line\n",
    "def separate_dataset(trainset):\n",
    "    datastring = []\n",
    "    datatarget = []\n",
    "    for i in range(len(trainset.data)):\n",
    "        data_ = trainset.data[i].split('\\n')\n",
    "        # python3, if python2, just remove list()\n",
    "        data_ = list(filter(None, data_))\n",
    "        for n in range(len(data_)):\n",
    "            data_[n] = clearstring(data_[n])\n",
    "        datastring += data_\n",
    "        for n in range(len(data_)):\n",
    "            datatarget.append(trainset.target[i])\n",
    "    return datastring, datatarget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['adidas', 'apple', 'hungry', 'kerajaan', 'nike', 'pembangkang', 'thirsty', 'tn50', 'wawasan2020']\n",
      "28525\n",
      "28525\n"
     ]
    }
   ],
   "source": [
    "# you can change any encoding type\n",
    "trainset = sklearn.datasets.load_files(container_path = 'local', encoding = 'UTF-8')\n",
    "trainset.data, trainset.target = separate_dataset(trainset)\n",
    "print (trainset.target_names)\n",
    "print (len(trainset.data))\n",
    "print (len(trainset.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# bag-of-word\n",
    "bow = CountVectorizer().fit_transform(trainset.data)\n",
    "\n",
    "#tf-idf, must get from BOW first\n",
    "tfidf = TfidfTransformer().fit_transform(bow)\n",
    "\n",
    "#hashing, default n_features, probability cannot divide by negative\n",
    "hashing = HashingVectorizer(non_negative = True).fit_transform(trainset.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy validation set:  0.82541630149\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     adidas       0.92      0.74      0.82       309\n",
      "      apple       0.81      0.87      0.84       501\n",
      "     hungry       0.84      0.92      0.88      1048\n",
      "   kerajaan       0.83      0.78      0.81      1412\n",
      "       nike       0.86      0.81      0.83       292\n",
      "pembangkang       0.81      0.83      0.82      1500\n",
      "    thirsty       0.97      0.46      0.63        71\n",
      "       tn50       0.93      0.52      0.67       211\n",
      "wawasan2020       0.75      0.98      0.85       361\n",
      "\n",
      "avg / total       0.83      0.83      0.82      5705\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_X, test_X, train_Y, test_Y = train_test_split(bow, trainset.target, test_size = 0.2)\n",
    "\n",
    "bayes_multinomial = MultinomialNB().fit(train_X, train_Y)\n",
    "predicted = bayes_multinomial.predict(test_X)\n",
    "print('accuracy validation set: ', np.mean(predicted == test_Y))\n",
    "\n",
    "# print scores\n",
    "print(metrics.classification_report(test_Y, predicted, target_names = trainset.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy validation set:  0.761787905346\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     adidas       0.95      0.51      0.67       329\n",
      "      apple       0.98      0.59      0.74       431\n",
      "     hungry       0.79      0.93      0.86      1054\n",
      "   kerajaan       0.73      0.79      0.76      1396\n",
      "       nike       0.94      0.57      0.71       326\n",
      "pembangkang       0.67      0.87      0.76      1528\n",
      "    thirsty       1.00      0.04      0.07        54\n",
      "       tn50       1.00      0.07      0.14       230\n",
      "wawasan2020       0.93      0.87      0.89       357\n",
      "\n",
      "avg / total       0.80      0.76      0.74      5705\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_X, test_X, train_Y, test_Y = train_test_split(tfidf, trainset.target, test_size = 0.2)\n",
    "\n",
    "bayes_multinomial = MultinomialNB().fit(train_X, train_Y)\n",
    "predicted = bayes_multinomial.predict(test_X)\n",
    "print('accuracy validation set: ', np.mean(predicted == test_Y))\n",
    "\n",
    "# print scores\n",
    "print(metrics.classification_report(test_Y, predicted, target_names = trainset.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy validation set:  0.755477651183\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     adidas       0.97      0.58      0.73       329\n",
      "      apple       1.00      0.45      0.62       458\n",
      "     hungry       0.86      0.91      0.88      1032\n",
      "   kerajaan       0.73      0.80      0.76      1420\n",
      "       nike       0.97      0.57      0.72       331\n",
      "pembangkang       0.62      0.89      0.73      1510\n",
      "    thirsty       1.00      0.02      0.03        62\n",
      "       tn50       1.00      0.02      0.04       199\n",
      "wawasan2020       0.97      0.85      0.90       364\n",
      "\n",
      "avg / total       0.80      0.76      0.74      5705\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_X, test_X, train_Y, test_Y = train_test_split(hashing, trainset.target, test_size = 0.2)\n",
    "\n",
    "bayes_multinomial = MultinomialNB().fit(train_X, train_Y)\n",
    "predicted = bayes_multinomial.predict(test_X)\n",
    "print('accuracy validation set: ', np.mean(predicted == test_Y))\n",
    "\n",
    "# print scores\n",
    "print(metrics.classification_report(test_Y, predicted, target_names = trainset.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
